{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define bounding box around each aufeis feature of interest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "pj_obj_create: Open of /opt/conda/share/proj failed\n",
      "pj_obj_create: Open of /opt/conda/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "# %%bash\n",
    "# # test to see what GRIT looks like (thought about this instead of SWORD)\n",
    "\n",
    "# # subset the GRIT river network to a the eastern north slope of AK\n",
    "# cd ../\n",
    "# ogr2ogr -f GPKG GRITv06_reaches_NorthSlopeAK_EPSG4326.gpkg GRITv06_reaches_simple_NA_EPSG4326.gpkg -spat -151.524048 67.205182 -140.139127 70.222115 -spat_srs EPSG:4326\n",
    "\n",
    "# # for now, grit seems overly complex... don't want to track along messy centerline that have breaks around aufeis ...\n",
    "# # might also be good to look at merit hydro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Point, LineString, Polygon\n",
    "from pyproj import Transformer\n",
    "from netCDF4 import Dataset\n",
    "from scipy.spatial import cKDTree\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- paths & parameters ----------\n",
    "sword_nc_path = \"../Workspace/na_sword_v16.nc\"\n",
    "aufeis_shp_path = \"../Workspace/aufeis_locations.shp\"\n",
    "out_shp_path = \"../Workspace/polygon_aufeis.shp\"\n",
    "target_crs = \"EPSG:32606\"   # UTM zone 6N\n",
    "scale_maxwidth = 1.0        # possible scalar for max_width\n",
    "\n",
    "# Subset bbox in lon/lat EPSG:4326 \n",
    "lon_min, lat_min, lon_max, lat_max = -151.524048, 67.205182, -140.139127, 70.222115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Utility funcs ----------\n",
    "def var_from_group(nc_obj, groupname, varname):\n",
    "    \"\"\"Return numpy array for a variable inside a group.\"\"\"\n",
    "    return nc_obj.groups[groupname].variables[varname][:]\n",
    "\n",
    "def make_rotated_rectangle_from_segment(pt1, pt2, width):\n",
    "    \"\"\"\n",
    "    Construct a rotated rectangle polygon aligned with segment from pt1->pt2.\n",
    "    pt1, pt2 are (x,y) tuples in projected units.\n",
    "    width is total width in same units.\n",
    "    Returns shapely Polygon.\n",
    "    \"\"\"\n",
    "    x1, y1 = pt1\n",
    "    x2, y2 = pt2\n",
    "    dx = x2 - x1\n",
    "    dy = y2 - y1\n",
    "    seg_len = math.hypot(dx, dy)\n",
    "    if seg_len == 0:\n",
    "        w2 = max(1.0, width / 2.0)\n",
    "        return Point(x1, y1).buffer(w2, cap_style=2)\n",
    "    angle = math.atan2(dy, dx)  # direction of segment\n",
    "    perp_x = -math.sin(angle)\n",
    "    perp_y = math.cos(angle)\n",
    "    half_w = width / 2.0\n",
    "    p1 = (x1 + perp_x * half_w, y1 + perp_y * half_w)\n",
    "    p2 = (x2 + perp_x * half_w, y2 + perp_y * half_w)\n",
    "    p3 = (x2 - perp_x * half_w, y2 - perp_y * half_w)\n",
    "    p4 = (x1 - perp_x * half_w, y1 - perp_y * half_w)\n",
    "    return Polygon([p1, p2, p3, p4, p1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 5 aufeis features. CRS: EPSG:32606\n"
     ]
    }
   ],
   "source": [
    "# ---------- Load aufeis features ----------\n",
    "aufeis = gpd.read_file(aufeis_shp_path)\n",
    "aufeis = aufeis.to_crs(target_crs)\n",
    "print(f\"Loaded {len(aufeis)} aufeis features. CRS: {aufeis.crs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes in bbox: 21126 / 1683122\n",
      "Centerline points in bbox: 128111 / 10304258\n"
     ]
    }
   ],
   "source": [
    "# ---------- Open netCDF and subset by bbox ----------\n",
    "nc = Dataset(sword_nc_path, mode=\"r\")\n",
    "\n",
    "# Read node lon/lat and node ids\n",
    "node_lon = var_from_group(nc, \"nodes\", \"x\")[:]       # degrees east\n",
    "node_lat = var_from_group(nc, \"nodes\", \"y\")[:]       # degrees north\n",
    "node_id_all = var_from_group(nc, \"nodes\", \"node_id\")[:]\n",
    "\n",
    "# Mask nodes inside bbox\n",
    "mask_nodes = (\n",
    "    (node_lon >= lon_min) & (node_lon <= lon_max) &\n",
    "    (node_lat >= lat_min) & (node_lat <= lat_max)\n",
    ")\n",
    "node_idx_sub = np.nonzero(mask_nodes)[0]\n",
    "print(f\"Nodes in bbox: {len(node_idx_sub)} / {node_lon.size}\")\n",
    "\n",
    "# Subset node arrays\n",
    "node_id = node_id_all[node_idx_sub].astype(int)\n",
    "node_lon = node_lon[node_idx_sub].astype(float)\n",
    "node_lat = node_lat[node_idx_sub].astype(float)\n",
    "node_max_width = var_from_group(nc, \"nodes\", \"max_width\")[:][node_idx_sub].astype(float)\n",
    "\n",
    "# Read centerlines (global arrays) and subset by bbox\n",
    "cl_x = var_from_group(nc, \"centerlines\", \"x\")[:]   # degrees east\n",
    "cl_y = var_from_group(nc, \"centerlines\", \"y\")[:]   # degrees north\n",
    "cl_id = var_from_group(nc, \"centerlines\", \"cl_id\")[:]  # int per point\n",
    "cl_node_id_2d = var_from_group(nc, \"centerlines\", \"node_id\")[:]  # shape (num_domains, num_points)\n",
    "\n",
    "# mask centerline points in bbox\n",
    "mask_cl = (cl_x >= lon_min) & (cl_x <= lon_max) & (cl_y >= lat_min) & (cl_y <= lat_max)\n",
    "cl_idx_sub = np.nonzero(mask_cl)[0]\n",
    "print(f\"Centerline points in bbox: {len(cl_idx_sub)} / {cl_x.size}\")\n",
    "\n",
    "# Subset centerline arrays\n",
    "cl_x_sub = cl_x[cl_idx_sub].astype(float)\n",
    "cl_y_sub = cl_y[cl_idx_sub].astype(float)\n",
    "cl_id_sub = cl_id[cl_idx_sub].astype(int)\n",
    "cl_node_id_sub = cl_node_id_2d[:, cl_idx_sub]  # keep domain dimension\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transforming coordinates to EPSG:32606 ...\n"
     ]
    }
   ],
   "source": [
    "# ---------- Transform lon/lat -> UTM (target_crs) ----------\n",
    "transformer = Transformer.from_crs(\"EPSG:4326\", target_crs, always_xy=True)\n",
    "nodes_x_utm, nodes_y_utm = transformer.transform(node_lon, node_lat)\n",
    "nodes_xy = np.vstack([nodes_x_utm, nodes_y_utm]).T\n",
    "\n",
    "cl_x_utm, cl_y_utm = transformer.transform(cl_x_sub, cl_y_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nodes with centerline points in subset: 21166\n"
     ]
    }
   ],
   "source": [
    "# ---------- Build mapping node_id -> ordered list of (cl_id, xutm, yutm) ----------\n",
    "CL_FILL_INT = -9999\n",
    "num_domains, num_points_subset = cl_node_id_sub.shape\n",
    "cl_by_node = defaultdict(list)\n",
    "\n",
    "for d in range(num_domains):\n",
    "    node_ids_for_domain = cl_node_id_sub[d, :]\n",
    "    valid_mask = (node_ids_for_domain != CL_FILL_INT)\n",
    "    valid_indices = np.nonzero(valid_mask)[0]\n",
    "    for idx in valid_indices:\n",
    "        p = int(idx)\n",
    "        nid = int(node_ids_for_domain[p])\n",
    "        # find the corresponding cl_id index in the subset arrays\n",
    "        cl_idx_global = cl_idx_sub[p]  # p indexes into cl_idx_sub's order\n",
    "        # Use the cl_id_sub order: the arrays cl_x_utm/cl_y_utm are aligned with cl_id_sub\n",
    "        cl_val = int(cl_id_sub[p]) if cl_id_sub[p] != CL_FILL_INT else None\n",
    "        if cl_val is None:\n",
    "            continue\n",
    "        cl_by_node[nid].append((cl_val, float(cl_x_utm[p]), float(cl_y_utm[p])))\n",
    "\n",
    "# Sort each node's centerline points by cl_id\n",
    "for nid in list(cl_by_node.keys()):\n",
    "    cl_by_node[nid].sort(key=lambda t: t[0])\n",
    "\n",
    "print(f\"Nodes with centerline points in subset: {len(cl_by_node)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- KDTree for snapping ----------\n",
    "kdt = cKDTree(nodes_xy)\n",
    "\n",
    "# Map node_id array index for quick lookup (node id -> index in nodes_xy arrays)\n",
    "nodeid_to_index = {int(nid): i for i, nid in enumerate(node_id)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------- Iterate aufeis, snap, build polygon ----------\n",
    "polys = []\n",
    "attrs = []\n",
    "\n",
    "for idx, row in aufeis.reset_index().iterrows():\n",
    "    # row has 'index' (original index) and geometry + length_m etc.\n",
    "    orig_index = int(row['index'])\n",
    "    length_m = float(row['length_m'])\n",
    "    geom = row.geometry\n",
    "    if not isinstance(geom, Point):\n",
    "        geom = geom.centroid\n",
    "    px, py = geom.x, geom.y\n",
    "\n",
    "    # nearest node (in UTM)\n",
    "    dist, node_idx_local = kdt.query([px, py])\n",
    "    node_idx_local = int(node_idx_local)\n",
    "    snapped_node_id = int(node_id[node_idx_local])\n",
    "    node_w = float(node_max_width[node_idx_local]) * scale_maxwidth\n",
    "    if math.isnan(node_w) or node_w <= 0:\n",
    "        # fallback to width variable from nodes group\n",
    "        try:\n",
    "            width_all = var_from_group(nc, \"nodes\", \"width\")[:]\n",
    "            # need to subset same way\n",
    "            width_sub = width_all[node_idx_sub]\n",
    "            w_fallback = float(width_sub[node_idx_local])\n",
    "            node_w = w_fallback if (not math.isnan(w_fallback) and w_fallback > 0) else 1.0\n",
    "        except Exception:\n",
    "            node_w = 1.0\n",
    "\n",
    "    # Get centerline point list for snapped_node_id\n",
    "    cl_list = cl_by_node.get(snapped_node_id, [])\n",
    "\n",
    "    if len(cl_list) >= 2:\n",
    "        # Build LineString from ordered cl_list\n",
    "        cl_coords = [(t[1], t[2]) for t in cl_list]\n",
    "        ln = LineString(cl_coords)\n",
    "        # project aufeis point onto ln (both are UTM)\n",
    "        proj_dist = ln.project(Point(px, py))\n",
    "        half = length_m / 2.0\n",
    "        start_d = max(0.0, proj_dist - half)\n",
    "        end_d = min(ln.length, proj_dist + half)\n",
    "        p_start = ln.interpolate(start_d)\n",
    "        p_end = ln.interpolate(end_d)\n",
    "        rect = make_rotated_rectangle_from_segment((p_start.x, p_start.y), (p_end.x, p_end.y), node_w)\n",
    "    else:\n",
    "        # fallback: compute rectangle using node's two extreme cl points (try reading cl_ids from nodes/cl_ids)\n",
    "        # If no centerline, fallback to small buffered square around node coordinate.\n",
    "        node_xy = nodes_xy[node_idx_local]\n",
    "        rect = Point(node_xy[0], node_xy[1]).buffer(max(1.0, node_w/2.0), cap_style=2)\n",
    "\n",
    "    polys.append(rect)\n",
    "    attrs.append({\n",
    "        \"aufeis_index\": orig_index,\n",
    "        \"snapped_node_id\": snapped_node_id,\n",
    "        \"node_max_width\": node_w,\n",
    "        \"length_m\": length_m\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote 5 polygons to ../Workspace/polygon_aufeis.shp\n"
     ]
    }
   ],
   "source": [
    "# ---------- Build GeoDataFrame and save ----------\n",
    "out_gdf = gpd.GeoDataFrame(attrs, geometry=polys, crs=target_crs)\n",
    "\n",
    "# merge original aufeis attributes by original index\n",
    "aufeis_reset = aufeis.reset_index().rename(columns={\"index\": \"aufeis_index\"})\n",
    "out_gdf = out_gdf.merge(aufeis_reset.drop(columns=\"geometry\"), on=\"aufeis_index\", how=\"left\")\n",
    "\n",
    "# save as shapefile\n",
    "out_gdf.to_file(out_shp_path, driver=\"ESRI Shapefile\")\n",
    "\n",
    "print(\"Wrote\", len(out_gdf), \"polygons to\", out_shp_path)\n",
    "\n",
    "# close netCDF\n",
    "nc.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
